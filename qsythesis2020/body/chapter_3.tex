% !Mode:: "TeX:UTF-8" 

\BiChapter{研究可编程设备加速主机侧网络方法}{NIC}


\BiSection{本章引论}{}

\BiSection{问题背景}{aa}

%有什么东西软件做不好的，
%
%为什么要选流量工程 和 压缩加速。一定要好好想明白。 每包计算是最费劲儿的。
%流量系统背景和测量背景， %1
%
%软件流量捕捉 回放能力，

随着数据中心服务器网络接口容量快速增长，处理与网络数据相关的服务已越来越耗费主机CPU的计算资源。主机虚拟化、流量工程、网络监管等功能在现代化网络管理中已经占据重要的位置。尽管目前发展出一系列RDMA、DPDK等基于网卡的网络数据包快速搬运架构，但它们只针对于块儿数据的传递进行了优化，对于需要“每包处理”的任务依然没有良好的对策。



本文将复杂网络计算问题分为两类任务类型，一种类型是由于数据包到达频繁而触发的大量计算，也许这类型计算并不复杂（处理器使用几条指令即可完成计算），但由于需要对每个数据包都进行处理从而导致计算量庞大、CPU无法胜任，例如查找、转发、分类等。第二种类型是由于计算过程复杂（处理器需要耗费多条指令才可完成计算），导致CPU无法提升针对每个数据包处理的速度，进而造成网络分发数据包个数降低、性能需求无法胜任，例如防火墙、安全分析等。数据中心运营商面对着不断增长的功能需求和性能需求，同时也面对着需要降低运营成本提升能源利用率和绿色环保。

网络随路计算（in-network computing）是一种解决网络程序性能差的有效途径。网络随路计算是指在网络数据传输链路中增加特定功能的硬件设备，使得数据包在传送到主机内部之前，就完成了网络任务中的相关计算需求。当计算从主机内，下方到了网络内后，这便释放了软件处理瓶颈，可以节约数据中心内宝贵的CPU处理资源。但主机内的计算任务并不能够全都被硬件卸载，因而我们需要选取可编程数据平面来完成这件事。前文提到过三类可编程网卡他们分别是：基于可编程ASIC的智能网卡，基于NPU的智能网卡，以及基于FPGA的智能网卡。首先本文分析基于ASIC的智能网卡是非“图灵完全”的可编程硬件，尽管其处理性能优异，但无法支持灵活配置，因而本文不考虑。其次基于NPU的智能网卡，NPU由众核处理器架构组成，可提升处理并行度，但这是基于批处理的计算模型。针对目前流式计算和有状态计算，因NPU每核处理性能低，从而导致NPU方案整体运行性能差。

本文从上述两类问题中各选取了一个应用场景，来说明使用基于FPGA的智能网卡具备强大的“每包处理”能力，以及强大的“复杂计算”能力。最重要的是FPGA可以支持网络内流式计算模型，本文在后面提出了一种在FPGA针对流式计算需求的DC抽象方法，可以将有前后状态依赖的“复杂计算”任务卸载到基于FPGA的可编程硬件。

%The Case For In-Network Computing On Demand 分类举例说明



\BiSection{系统架构}{aa} %1

\BiSubsection{软件向硬件卸载分析}{aa}

CPU通过循环取指令等操作，完成通用的可计算任务。计算的数据通常有前后依赖关系，CPU对于此类计算效率较低：由于中间计算状态在计算完成之后必须放回数据存储区，而下次重新拿回状态数据又需要再次搬运，数据在计算核心与存储池之间多次往返对计算最终结果是无意义操作。而即使使用众核处理器也无法优化此过程，虽然众核处理器可并行计算多个任务，但同一时刻每核心与其他核心处理内容并无关联。对于前后有依赖关系的处理，并行并不能加速其中一组数据的处理进程。在网络领域亦是如此，网络数据包到达密度很大，留给每个包的处理时间很有限，然而通常一个CPU无法在如此短时间内真正处理完一个包的触发计算。


1）软件处理延迟大。

目前高速网络处理器可以设计为核间流水线模式，每个核只处理固定的一步计算。当一个数据包触发的计算包括多个前后依赖计算时，人们使用多个核串行处理这组计算。即每个核心领取一个固定的快速处理任务，这样每个核都可以以最快的速度处理完当前步骤，然后交给后续核心继续处理。这样数据包的处理吞吐其实就可以达到某一个核心的最大速度，而处理延迟则是这些核心之间传递完整一次的时间。不难发现，数据在众核之间搬运会遇到访存时间过长、访存请求冲突等现象。虽然使用CPU可以获取很大的灵活性，但这种方式进一步增大了每个数据包处理的时延。如今在云端加速AI计算的场景下，高频次小包、数据快速到达的需求越来越高，这使得以CPU处理网络数据包造成很大的云计算性能瓶颈。后续我们通过本文所举的例子可以明显提现这一点。

2）软件处理时间精度低。

同时，由于共享内存与总线架构，数据在CPU核心、存储池之间搬运会造成随机的请求冲突、甚至计算等待，这将中断顺序串行处理节拍。由于这条处理链中的处理速度会受到这条处理链最慢处的制约，因而处理链的性能表现总以最慢的瓶颈向外表现。
软件的处理收到操作系统的指挥，操作系统一般会划分时间片区来分配给每一个待处理的任务。虚拟化的操作系统内有很多任务进程，操作系统会划分很多时间片区。这也进一步降低了CPU的专用任务处理性能，还带来处理时间精度不足的现象。后续我们通过本文所举的例子可以明显提现这一点。

3）软件功能向硬件卸载。

卸载是指将工作负载从一个实体转移到另外一个实体上去。软件功能的卸载遵循一定原则：

\begin{itemize}
	\item 新实体可以做与原来实体相同的工作，但资源耗费更少。
	\item 新实体比另外一个实体更快地完成某种类型的工作。
	\item 新实体有能力做除此外的其他任务。
\end{itemize}

硬件功能卸载已经广泛使用在计算机领域。早期，开发人已经把音视频处理从CPU完全卸载到图形处理器和音频芯片中。此外还有一些例子：数据包校验计算卸载到网卡，传输大宗数据时使用DMA控制器，在硬盘控制器中做数据错误恢复。事实上，从CPU中卸载出来的功能都比单纯由CPU执行能源效率高很多。但本文并不是强调CPU无用论，因为CPU是整个服务器中最具有灵活性的器件。卸载任务应该是简单、机械的，CPU是系统内可编程、可运行花样繁多的算法，从而具有很高的难以替代性。

卸载通常是一种优化技术，与其他优化方法一样，仅在合适场景下适用，虽然他增强了计算效率，但这种卸载方式并不是完美的：

\begin{itemize}
	\item 增加了软硬开发人员的工程任务量。
	\item 增加新的硬件，使系统结构复杂。
	\item 设计制造新硬件，增加研发周期、增加使用成本。
	\item 由于大量装配特殊器件，系统可移植性降低。
\end{itemize}

对于灵活多变的网络流量的处理任务，大多为分步骤且数据包信息前后依赖关系高。前文提到，如果使用基于NPU的可编程网卡，虽然灵活性可以被满足，但依然存在性能问题（单核性能低，单个数据包处理延迟大）。使用基于可编程硬件（FPGA）的智能网卡卸载网络功能，可以有效解决上述问题。


\begin{table}[!ht]
	\renewcommand{\arraystretch}{1.2}
	\centering\wuhao
	\caption{FPGA的优势与劣势} \label{table:FPGAstrengthandweakness} \vspace{2mm}
	\begin{tabularx}{\textwidth}{*{2}Y}
		\toprule[1.5pt]
		FPGA所擅长的处理内容 & 不适宜使用FPGA处理的任务 \\
		\midrule[1pt]
		流式数据通路（视频处理） & 多决策算法 \\
		并行算法 & 递归 \\
		低延迟、确定延迟系统 & 依赖于其他大型软件库 \\
		与硬件接口紧邻 & 浮点数学计算 \\
		\bottomrule[1.5pt]
	\end{tabularx}
\end{table}

表\ref{table:FPGAstrengthandweakness}展示了使用FPGA作为卸载功能目的实体与CPU和ASIC对比的相对优劣点。虽然FPGA完全有能力完成分支多且复杂的决策算法，但相比于CPU，在FPGA上实现会付出更多编码时间，不如使用通用处理器经济收益好。另外相对软件而言，FPGA的处理过程具有精确无抖动（jitter-free）的时序效果。虽然独特优化的软件代码可以近似达到这种效果，但它依然严重地受到调度器，中断，不同处理路径的影响而产生抖动。


\BiSubsection{软件算法的硬件抽象方法}{aa}

在高性能的大数据领域，批处理技术已经可以满足非常多的使用场景，但随着数据时效性价值提升，一种流式计算概念被提出。流式计算是实时的，常驻的，与Hadoop，MaxCompute，Spark等系统不同（它们是离线批处理），流式计算对延迟属性要求更为苛刻。而目前在大数据和高性能网络中的处理就更需要考虑如何利用FPGA来加速流式计算的需求。
%阿里巴巴 大数据page70 流式计算的特点
\begin{figure}[!ht]
	\centering
	\includegraphics[scale=1]{fpgaprogramabstraction.pdf}
	\caption{FPGA硬件编程抽象} \label{fig:fpgaprogramabstraction}
\end{figure}

1）FPGA编程抽象。
		
基于FPGA的可编程逻辑，可以完成很多种计算。在软件思维转向硬件化的时候，如图\ref{fig:fpgaprogramabstraction}所示，给出了三种并行化加速方法：同一种功能（$F(x)$）的复制展开并行；一组数学计算的内部隐含（四则运算分配律和结合律）逻辑并行；分支选择的选路并行。



2）功能卸载的“数据---计算”DC抽象方法。

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=1]{dcprinciple.pdf}
	\caption{FPGA加速流式计算的DC抽象方法与原则} \label{fig:dcprinciple}
\end{figure}

网络计算卸载到FPGA中，需要在FPGA的并行计算加速基础上，引入一种适合于流式计算FPGA的编程抽象，本文称其为“数据---计算”模型（Data--Computing，DC抽象）。如图\ref{fig:dcprinciple}所示，每个节点内都包括一个或一系列功能（函数$F(x), G(x)$等），本文称其为“计算”，在不同的计算节点之间是数据流（以数据包为驱动），本文称其为“数据”。如何排列和组织这种“计算和数据”是DC抽象的核心内容。一般数字电路会设计为时序逻辑，也就是以时钟周期时间跨度为节拍的计算。各个逻辑块需要在同一个节拍内计算出相应结果。对于在数据处理时前后无关的计算可以归到内部并行中去，所以流式数据处理方法需要挑出数据计算时有前后相关的部分，并把它们按照一定拓扑串联起来。DC抽象基于上述分析提出在FPGA内处理网络流式计算的加速的原则：

\begin{itemize}
	\item 在流水线的每一级具有确定的节拍数。
	\item 数据前后内容具有依赖性。%流式处理要分层，只把前后数据相关的分层，
	\item 有固定的流水线拓扑，但是数据在拓扑间可任意流动。
\end{itemize}

下面将重点介绍本文如何利用DC抽象原则，对基于可编程硬件的网络高时效性网络任务和高密度计算任务卸载加速的研究。

%上面的部分再画个图吧。。。。。。

\BiSection{网络流量捕获与回放}{aa} %4

\BiSubsection{概述}{aa}

网络测量和分析是监控、调试和管理网络，进而设计反馈和优化网络结构以及改善网络服务质量的重要手段。近年来，互联网与网络应用的不断发展，网络内服务器遭遇的各类破坏与攻击也随之与日俱增，网络安全问题日益手段人们的重视。因此，在大型数据中心内，对入侵攻击的检测与防范、保障信息系统和网络系统安全已经成为研究人员的共识。为了快速确定网络攻击的发生，如何设计一种可以实时检测网络流量的网关系统变得异常重要。例如，当网关系统发现大规模DDoS攻击时，可以主动做出丢包等拦截动作，但是对正常数据包应采取放行策略。

这类系统对低传输时延、高吞吐迫切需求。对于复杂网络协议、和内容的分析，一般需要使用大型服务器的多核CPU。由于网络中流的数目很多，因此可以将不同的流量分配到不同的并行CPU中去做并行入侵检测。但对极高流速的网络数据包的捕获，分发等工作却面临很大的性能压力。经过检测系统处理完的数据包还需按先后顺序汇聚，保证多核并行系统不会对原始流量数据包的内在逻辑产生影响。因其特殊的处理需求，以及数据包高吞吐特性，因此安全监测系统的网络收发部分是一项极为重要的挑战。因此本文的主要研究点服务器端网络数据的接入、分发与回流，其余的内容检测等属于上层软件应用，不在本文讨论范围之内。





\BiSubsection{问题分析}{aa}

对于流量接入而言，其挑战在于如何快速地捕获足够的网络流量。经典的如TCPDump以及TCPTrace等基于软件的流量捕获工具，可以完成将某网络接口数据包镜像并缓存的功能。简单来说数据包首先到网卡，然后通过软中断的形式触发内核对其处理，通过DMA写入内存，最后再被应用程序读取。软件首先使数据包经过BPF（伯克利包过滤，BPF能够通过比较第2、3、4层协议中各个数据字段值的方法对流量进行过滤）包过滤器，通过过滤的数据包放入bufferQ缓存（给应用程序读取数据包的缓冲队列），tcpdump就是从bufferQ中抓取数据包。不难发现，这类操作必须由内核态到用户态两次传输，一个数据包需要经过多次CPU处理循环。

其主要问题有两点：操作系统时间精度低，软件处理丢包严重性能低下。首先，时间精度低。为了记录数据包接入的速度特征分布，我们需要对每个数据包首增加到达时间戳，这样在令数据包回流网络使可最大限度的保证不影响对每个流的网络服务特性。数据包到达后发送软中断，软件为其添加时间戳时已经有了系统误差。这种误差来自于操作系统时间管理与任务轮询的不精确性（例如图\ref{fig:jitter}\footnote{本实验指在测试软件协议栈的系统时间精度，一种简单方式是通过PING协议的RTT时延来作为参考。如果软件处理稳定性很高，则每次定点RTT的数值应保持稳定。由于目前云服务商在系统内禁止网关的PING服务，本文通过协议栈与本地回环（127.0.0.1）之间的RTT来近似代表，并计算出了用户态到本地网关之间的RTT抖动。}）。这样的不精确会给流分布的记录造成误差，最终导致某一段数据流抖动（jitter）增大，改变数据流特性。加之在真实场景中，软件收发包通过虚拟层，协议栈，内核态，用户态等多步骤处理，累计的总体时间抖动很大。第二，性能低下。目前在linux服务器环境下的捕获的丢包率偏高(例如图\ref{fig:tcpdumploss})，与真实网络接口速度差距过大。由于需要对串行数据中每个数据包依次增加时间戳，因而在此过程中无法引入软件并行，从而仅依靠单核极易造成性能瓶颈。



\begin{figure}[htbp]
	\centering
	\begin{minipage}[t]{0.48\textwidth}
		\centering
		\includegraphics[scale=1]{jitter.pdf}
		\caption{软件环境网络协议栈发包时间精度} \label{fig:jitter}
	\end{minipage}
	\begin{minipage}[t]{0.48\textwidth}
		\centering
		\includegraphics[scale=1]{tcpdumploss.pdf}
		\caption{TCPdump收包工具丢包率} \label{fig:tcpdumploss}
	\end{minipage}
\end{figure}

流量回放技术基于流量捕获基础之上完成，除前文提到用于实时入侵系统外，在离线性能测试、模拟攻击等领域还有重要作用。人工构造的流量并不能完全重现真实环境中的网络，研究人员利用流量回放还能用以测试实时网络安全系统。

为应对如今超大规模接口带宽，基于软件的流量捕获和回放系统遇到了极大的可扩展性问题，已无法满足目前的行业需求。本文以解决此问题为目标，在主机端使用可编程硬件网卡技术，来大幅度提升服务器捕获回放数据包性能。



\BiSubsection{设计}{aa} %总述，本章将实现，，，，然后，分两部分写。

网络流量的捕获、统计与回放是统一的一套体系，在软件层面使用使用多核间的流水线完成加速。在流水线中的所有数据包，都可以看做同时受到各个前后功能的处理，这样可以大幅增加吞吐。本文的基本思路是将软件层的所有瓶颈功能全部下放到可编程硬件，只留轻负载的文件存储管理系统。当前基于软件的网络流量捕获系统收到数据包后由CPU处理所有操作（图\ref{fig:caprepsoftway}）。对此类型架构的一种典型优化方式为使用多核CPU并行加速。首先为每个CPU核心分配不同的任务，且应该尽量使任务负载均匀分配。之后数据流凭借共享内存的形式，依次串行通过所有功能核心。这样使多核CPU完成了类似流水线的结构。由于每一个核心不可能得到真正公平的任务负载，所以系统的最大处理能力受到链路内最窄处的制约。



\begin{figure}[htbp]
	\centering
	\begin{minipage}[t]{0.48\textwidth}
		\centering
		\includegraphics[scale=1]{caprepsoftway.pdf}
		\caption{基于软件的设计思路} \label{fig:caprepsoftway}
	\end{minipage}
	\begin{minipage}[t]{0.48\textwidth}
		\centering
		\includegraphics[scale=1]{caprephardway.pdf}
		\caption{基于可编程智能网卡的设计思路} \label{fig:caprephardway}
	\end{minipage}
\end{figure}

如图\ref{fig:caprephardway}所示为本文基于FPGA的硬件可编程智能网卡系统架构。本文将之前在软件中的大部分计算密集型任务全部下放到硬件。 与软件系统相比，本文提出软硬一体化网络流量捕获回放系统有如下优点：

\begin{itemize}
	\item 时间戳精度高。FPGA运行主频为125MHz，硬件逻辑可精确地在数据包到达时刻将系统时间插入数据包字段内。硬件系统使用相对时间，由于数据包接入与回放只要保障相对顺序即可，时间戳无需使用操作系统内的绝对时间。125MHz主频对应每一个时钟周期8ns，因此系统对数据包的监测处理时间误差以8ns为单位，远远优于于软件协议栈时间精度（$10^3-10^6$ns）。
	\item 时间同步性强。网卡中的相对时间计数器由一组寄存器构成。FPGA内寄存器位置分布灵活，逻辑与寄存器组同步性好，这为数据包各个阶段的逻辑操作提供了统一的时间评价尺度。
	\item 流水线内无性能狭窄处。根据前文提到DC抽象方法，在数据计算密集型场景下，硬件系统内各个处理阶段应该有相同的节拍个数，因此保障了整个处理链路可预知的性能预期。
	\item 消除软件性能瓶颈。系统将密集型计算和控制卸载到硬件，在CPU中只保留了数据的存储管理功能。如果系统希望把捕获的数据暂存起来，留以后离线分析或者其他时间回放，则需要把大量数据包内容存储到计算机硬盘内。这部分操作相比之前的密集型计算负载更“轻”不是系统瓶颈，且易于并行扩展。它需要与高层文件系统、I/O调度等交互，因此保留在软件层较为合适。
\end{itemize}

本文在流量捕获回放系统中间还加入了一种高存储优化的统计系统，此内容将在下一节单独介绍，不会影响本节内容安排。

\BiSubsection{电路实现以及协议}{aa}

如图\ref{fig:arccaprep}所示为流量捕获回放系统FPGA内硬件核心逻辑架构，接下来分别介绍设计的核心思路。其中捕获通路中的统计电路采用了一种实时的带有数据压缩方式的设计，内容较为复杂。为了不影响论文结构层次，将其放在下一小节单独介绍。

1）数据包硬件接口。

在智能网卡上，数据包首先经由物理网口（phy\_port）进入板上电路，此时需要将网络通信的物理层信号协议转换为二层数据帧。一般由光电转换模块和物理层芯片结合处理。帧封装的数据包数据信息是串行高速总线协议，MAC核逻辑将其转换为低速率的并行总线，并分离出数据的伴随时钟信号。之后为数据流（数据字）添加统一格式标记（控制字）。

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=1]{arccaprep.pdf}
	\caption{流量捕获与回放系统数据通路FPGA核心逻辑架构} \label{fig:arccaprep}
\end{figure}

2）流量捕获---数据包处理通路。

在数据通路中，本文需要增添三个硬件模块：时间戳模块、流量均衡分类器和多路输出调度器。

\begin{itemize}
	\item 时间戳模块。为每个到达的数据包添加实时的64bit时间，数据总线结构如图\ref{fig:pktstruct}所示。FPGA数据通路主频为125MHz，每个时钟周期时长8ns。时间戳寄存器每个时钟周期都被触发一次自增8的加法操作。每个数据包到达有严格先后顺序，所以每个数据包的时间戳都是独一无二的。64bits数据可以表达正整数范围达到$1.8\times10^{19}$以上，从ns换算成年，相当于地球年的500年以上，数据位宽足够使用。
	\item 流量均衡分类器。流量捕获系统将数据包从网口传递到硬盘模组，整个链路中最有可能成为瓶颈的地方是硬盘的I/O驱动，由于普通机械硬盘真实外部读写性能只有1.5Gbps（SATA接口）左右\footnote{当时实验完成的板卡是以PCIe2.0$ \times $8为标准的主板插槽卡。互通总带宽为$ 5Gbps\times 8=40Gbps $，因而PCIe总线不是系统瓶颈。}，这极大地限制了系统的性能。为了增大系统的最终捕获速度，本文将大流量通过硬件哈希算法分类为$N$条子流量。子流量的流速期望就变为之前总流量的$\dfrac{1}{N}$。哈希函数（CRC-16）的输入为网络流量数据包前五元组信息（目的IP地址，源IP地址，目的端口号，源端口号，协议标签）组成的104bits二进制数字。对于不包含五元组信息的数据包，可使用二层MAC地址（96bits）后补齐0，来组成新的104bits数字。CRC-16算法将输入数字转换成一组16bits的短数字，不同hash函数会转换出不同的值。但对于同一个hash函数不同的输入也可能得到相同的结果，最后我们选取结果的最后2bits位作为标记，以区分最终的缓存分支队列。一般的CRC函数都可以在同一个时钟周期内出结果，不会影响流水线性能。
	\item 多路输出调度器。多路调度器读取hash函数的输出结果并将此时的数据包按结果分发向不同队列。最终并行队列会分别上传到软件层，分别储存到不同的硬盘中。

\end{itemize}

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=1]{pktstruct.pdf}
	\caption{数据包格式与控制字标志} \label{fig:pktstruct}
\end{figure}

3）流量回放---数据包处理通路。

流量回放是流表捕获的逆过程，数据从多列硬盘中读出并发送到FPGA内部多列缓存中。FPGA根据多队列数据流包头时间戳大小重新组合为一组数据流向板卡外发送，从而使系统可以完整模拟数据流现场状况。本文在回放通道中设计了两个硬件模块：时间比较模块、延迟开关。

\begin{itemize}
	\item 时间比较模块。此模块读取所有队列中的时间戳，并返回时间最小的时间戳所在的队列编号。在软件中，查找$N$个数据中的最小值时间复杂度为$ O(N) $。利用硬件逻辑天然的并行优势，可以对N组数据两两比较得出结果后，再对结果两两比较，这样只需要$ O(log N) $级比较即可输出最小值。值得注意的是，只有在比出最小值后取出队列首包，弹出后续包时间戳数据后，才能进行第二回合的比较。如果队列数过大，也许在同一个时钟周期内逻辑做不完比较儿产生输出不稳定的“竞争与险象”，从而得到错误的结果。例如，输入队列有64条，比较器的层数有6（$ log_264 $）层，从中找出最小值需要至少2个周期或者3个周期时间\footnote{具体耗费时延与选用FPGA器件特性有关，例如更低nm制程响应速度越快，也与运行主频有关。}。如果查询时间超过一个时钟周期，数据在流水线中必然无法实现“背靠背”处理，总体处理流程都需要等待最耗时的这一级。
	\item 延迟开关。当选出最小时间戳的数据包后，并不是马上就可以发送出去，因为数据包与数据包之间有不固定的时间间隔。延迟开关的作用就是根据时间戳前后相对差值，让数据包等够所需的时间之后，再打开放行。这是提高数据包模拟真实环境相似程度的关键一步。
\end{itemize}

\BiSubsection{优化}{aa}

本小结主要分析流量捕获与回放系统的设计性能，并且探讨系统向目前主流网卡单网口100Gbps演进的优化方案。

上节提到，系统FPGA的主频选用125MHz，数据位宽64bits，则数据通路的总处理性能为$ P=8Gbps $。假设目标条件采集/回放速率$ T=4Gbps $，系统的瓶颈处：硬盘I/O需要扩充$ \dfrac{4}{1.5}=3 $倍，为保证性能可留有30\%的设计余地，则选取4块硬盘并行写入，总写入能力达到6Gbps。回放通路的逻辑瓶颈在于时间戳比较模块，4路数据可以在一个周期内比较完成，因而也满足处理性能大于实际需求。
由于当时技术协议发展水平受限，设计板卡的需求与现在相比略低。

如要适配当前高速率环境下的新协议，本文须重新分析设计瓶颈。FPGA内主要数据通路性能必须要大于100G（本文选取200MHz主频，512bits数据位宽），需要网卡拥有1路100G的网口，PCIe3.0$ \times $16（$8Gbps\times 16=104Gbps$）的互通带宽。目前主流高性能固态硬盘的读写性能达到10Gbps，因此我们需要选择16路分流并行存储，来解决存储I/O瓶颈，至此捕获通路无性能瓶颈。回放通路的性能瓶颈在于16个队列时间戳最小值比较，由于16队列需要至少4层并行2进1比较器，需要2个时钟周期才能完成。因此回放数据通路的处理性能只能达到100Mpps，但是这并不意味，处理性能也会下降一半（到50Gbps），只是在处理时无法满足最小包长的100G性能。如果通路内均为128字节包长，则系统也可达到100G线速。由于真实网络环境的平均包长度为600字节，留给每个数据包10个时钟周期的处理时间，因此在真实情况下性能是满足的。



\BiSection{统计---网络测量实时压缩}{aa} %4

\BiSubsection{概述}{aa}

随着云数据中心规模不断增长，基础设施架构自我设计制造成为主流，网络运营商因此有能力在网络监控和管理方面投入更多。目前许多基于云端和裸金属环境新提出的新应用（hypervisor，虚拟机管理）和算法（BBR，拥塞控制算法）对各种各样的网络测量结果产生极大的需求。网络测量是指在运行的网络中测量各种实时变动的状态参数，例如RTT、包数量、流容量大小、流容量速度、拥塞程度等。这里大部分参数都可用被动方式进行测量，即，对运行中网络不引入任何影响。被动测量对网络运营商是一种有效的工具，例如，网络计费、安全监控、流量调度等。被动测量的过程一般分为2部分：首先，测量装置收集网络中的信息（通常以数据包驱动计数）；第二，软件代理定期收集测量结果，并汇报上层控制层。


为解决监测系统软件实现效率低下的问题，研究人员提出一类“高速---低速”混合存储器更新方案。首先将流维护在高速缓存中（SRAM），此时SRAM的为每条流开辟空间较小，当SRAM中某条流溢出时，将此计数器值更新到DDR中，并为SRAM中对应的计数器清零。此方法有效减缓了DRAM的更新次数。但是会引入读值速度慢，硬件电路结构设计复杂等问题。此外，有工作提出将多个DDR用于并行统计以减小读值复杂度。然而随着数据量的增大，固定长度位宽的计数器依然有很高的溢出风险。

核心网络中，流量在转发节点总吞吐可达到上百T，流量数目可达到上百万，而流量转发节点数量也成百上千。对于精细地流量统计任务，每秒钟的更新量可能会达到150亿次\footnote{以10Tbps容量，转发64字节数据包计算。}，而因统计所耗费的存储空间需求可以达到数百兆\footnote{以10M条流量，每条流统计占用8字节宽度为例。}。因此软件代理不可能做到每包更新。因而大量的统计数据缓存在本地高速内存中。
如此庞大的统计任务一般会由分布式设备进行加速以及分流统计。尤其在数据中心网络，服务器的数量众多，因此在流量的端处进行统计能够尽量减少计算存储和汇报的性能压力。

上一章提到，云计算网络的设计理念为尽可能降低服务器CPU因网络任务而带来的大量消耗。由于网络任务本身是以数据包为驱动的，在大型数据中心的服务器往往对外网络性能可达到100G，数据包触发速度可达到150Mpps。网络功能每增加一步操作都会引起数量庞大的额外计算。此外，统计功能所占用的大量存储空间也成为设计挑战。CPU中的一二三级缓存（cache）虽然速度极快，但容量相对较小（1MB以内）。则等待更新值的存储位置必然须在大容量的外置存储器（DDR）中，DDR的随机读写性能极低，面对如此高频度的更新需求，系统I/O带宽成为瓶颈。即使都将数据暂存于快速cache中，以目前主流服务器CPU的2.5GHz左右时钟频率估计，更新频率大概也只有主频的十分之一或百分之一。两种因素互相钳制，导致使用主机CPU做细粒度统计开销极大，在CPU时间成本极大的云服务器领域，测量的效率问题成为亟待解决的一个难点。

%这里做个表，说明一下问题的几个要点。。。。乔思祎2020年7月10日21:46:17
\BiSubsection{问题分析}{aa}

被动测量在网络中是一种基础服务，尤其在拥有可编程智能网卡的大型数据中心内，为实现高性能测量提供了可行性。目前FGPA板载高性能存储容量都有几十MB，为实现各种应用提供了丰富的逻辑资源。然而如果将所有测量项目都实现在硬件中，依然会造成片上资源过度消耗。一方面，如果更产生一种新的测量需求，就重新开发硬件逻辑，这会对网络操作人员造成严重的时间浪费。另一方面，因为FPGA其他逻辑资源也需要消耗一定数量的存储，各个逻辑模块需要均衡地使用存储资源。而且为了FPGA后期布局布线，板载资源使用率尽量小于全部资源的70\%。这为本文研究基于FPGA的测量技术带来了极大挑战。

本文基于一种在硬件中实现的可压缩每流测量算法，有效地解决了此问题，从而可以在硬件上为每一条流保持统计信息，并且只使用少量的存储资源。即使使用大存储容量的器件，如果在实际应用中不使之压缩，统计学上总有计数器值溢出的风险。

\BiSubsection{基于硬件设计压缩效果与问题}{aa}

1）压缩算法

目前基于抽样的压缩统计方法是一种新兴的测量设计思想，因为只有一部分数据包被选中而送往统计模块，因此可以大大降低存储资源消耗并且同时能够减少计数器累加次数。简单抽样对于均匀流量有很好的效果，但是对于各个流量大小不一的场景，小流的误差值会很高。现阶段各类抽样方法中可被证明拥有最佳估计误差的压缩算法是DISCO算法。%加引用 乔思祎2020年7月11日11:06:36
DISCO算法是一种可被证明的无偏估计压缩方法，DISCO算法的核心目标是减少高速缓存内关于每条流计数器的位宽占用大小，并且对包个数以及字节数的压缩都可适用。

假设$ c $是计数器中存储的值（被压缩后的），$ n $为统计流量大小的真实值，令函数$ n=f(c) $表示二者的压缩数量关系，

\begin{equation} \label{discofunc}
f(c)=\frac{b^c-1}{b-1}
\end{equation}

式中，$ b>1 $，且$ b $为系统预先设置的固定值。可发现，$ c=f^{-1}(n) $为一个凸函数，统计数值c的增长趋势一定是亚线性的。随着$ c $增大，$ f(c) $可近似为一个指数函数。因此对于一个足够大的$ n $，函数$ f(\cdot) $可将原来线性增加的数值压缩至$ O(log~n) $。每当长度为$ l $的数据包到达系统，针对此数据包的计数器应增加$ \Delta(c,l) $，此时$ c $为当前计数器压缩后的值。根据定义$ f(c) $，可以得到$ \Delta(c,l)=f^{-1}(l+f(c))-c $。如果存储$ c $的计数器采用浮点数计数，则每次对$ c $算出新增$ \Delta(c,l) $并相加后，得到的c都可以无误差地表达$ n $的真实值。但存储带小数位的浮点数会会占用更多存储空间，为了提高存储效率，须假定$ c $是一个正整数。



\begin{algorithm}[ht]
	\caption{DISCO算法的估计方法 \label{discoa1}}
	\IncMargin{2em}
	\DontPrintSemicolon
%	\KwIn{$\mbf{x}(k), \quad \mu, \quad \mbf{w}(0)$}
%	\KwOut{$y(k), \quad \varepsilon(k)$}
	%
	$ v = random(0,1) $
	
	分别计算$ \delta(c,l) $和$ p_d(c,l) $
	
%	\For{$k=0,1,\cdots$}{
%		$y(k) = \mbf{w}^H(k)\mbf{x}(k)$ \tcp*{output signal}
%		$\varepsilon(k) = d(k)-y(k)$ \tcp*{error signal}
%		$\mbf{w}(k+1) = \mbf{w}(k)+\mu\varepsilon^{\ast}(k)\mbf{x}(k)$ \tcp*{weight vector update}
%	}

	\eIf{$ v \leq  p_d(c,l)  $}
	{$ c = c + \delta(c,l) +1 $ \tcp*{显然，当$ p_d $越大，$ c $最终向上取整的概率也越大}}
	{$ c = c + \delta(c,l) $ \tcp*{向下取整}}
\end{algorithm}

DISCO算法为努力将存储空间降低，引入了一种概率估计。由算法\ref{discoa1},系统可以获取整数估计后的压缩值$c$。其中$ \delta(c,l) $和$ p_d(c,l) $又下面公式定义：

\begin{equation} \label{discofun2}
\delta(c,l)=\lceil f^{-1}(l+f(c)) - c \rceil - 1
\end{equation}

\begin{equation} \label{discofun3}
p_d(c,l) = \dfrac{l+f(c)-f(c+\delta(c,l))}{f(c+\delta(c,l)+1)-f(c+\delta(c,l))}
\end{equation}

经一段时间的统计，监测设备向控制器上报计数值$ c $，控制器可由公式\ref{discofunc}快速反向推导而出，同时此估计方法的无偏性由论文\citeup{hu2013discount}给出。

%\begin{equation} \label{discofun4}
%e \leq \sqrt{\dfrac{b-1}{2}}
%\end{equation}

2）压缩算法硬件实现的效果

算法\ref{discoa1}中，除加减法与比较、判断之外，求函数$ f(\cdot)$与$ f^{-1}(\cdot) $的关键计算指令是求“指数”与“对数”。 计算机快速计算指数，一般使用自然底数变换法，辅以查询算数表以及对精度的层层消除，计算时间由原来硬解法的$ O(n) $，降低至20个指令周期左右。对数函数可以使用泰勒级数展开来近似计算，展开后计算方法均为指数乘法和加法，进而再次转化为指数复杂度的计算。

DISCO算法提出后，由软件实现并达到单CPU核心11Gbps处理能力。目前的服务器终端网络通信容量已由40Gbps向100Gbps发展，继续扩展CPU核数满足处理需求已显低效。网络通信包数据量巨大，即使使用快速算法也无法满足网卡的线速处理需求。100G网卡的数据包处理速度需求为大约150Mpps，数据通路内时钟主频不会超过300MHz。按上限计算，每个数据包的处理时间余量只有2个时钟周期（与快速算法相比，本文需求超过其能力1到2个数量级）。当然流水线设计方法可以把计算过程拉长到多节拍，从而保证吞吐量。但需要注意，本算法中数值$ c $有先后依赖关系。即，首包处理时，$ c $若没有完成更新，第二个数据包无法进入处理通道。因此从全局看，更新环节无法真正打开为多级流水线。

注意到，本文公式中所有的底数b为预先确定值，因此在实践中可以存储只关于b的计算表，这样可以最大限度减小计算复杂度，也比较节约计算用存储资源。假定计算表的深度为3072，宽度为32bits，选定$ b=1.006 $。系统支持的最大计数量等效于$ f(3072)=1.59\times10^{10}Bytes=15GB $。而计数器$ c $只需要12位（保存压缩后的值，$ 2^{12}=4096 $），而在不压缩的线性计数下则需要至少34bits的存储位宽（$ 2^{34}=1.71\times10^{10}>1.59\times10^{10}$）。即，对于指数计算需求$b^X (X \leq 3072)$，系统可以通过单周期查表方法获取结果。


使用查表法加速指数计算可获得很好的效果，但对数计算（$ log（X） $）即指数反函数计算无法实现一周期出结果。对数计算一般反向利用指数表进行二分估计。如图\ref{fig:logsearch}所示，左边为上述的指数预计算查找表。初始化值，c=0，f(c)=0，假设此时到来数据包长度为1500字节。根据公式\ref{discofun2}计算$ \delta(c,l)$，以及公式\ref{discofun3}计算$p_d(c,l) $。首先，在计算$ \delta(c,l)$时，最关键需要计算 $ f^{-1}(l+f(c)) $，带入$ l=1500 $、 $ f(0)=0 $，得到：

\begin{equation} \label{discofun3}
f^{-1}(1500+0) = x \rightarrow f(x)=1500 = \dfrac{b^x-1}{b-1}
\end{equation}

带入b=1.006，经过变换：

\begin{equation} \label{discofun3}
b^x=1500\times(b-1)+1\\
= 1500\times 0.006+1\\
=10
\end{equation}

因此，计算$ f^{-1}(1500+0) $的结果可以等价为：在指数计算表中查找当$ x $等于多少时指数值为10。由于指数值是非连续、非等差数列，查找方法只能使用二分法逼近。如图\ref{fig:logsearch}右侧所示，在3072个表项中从第一行开始进行二分查找至少需要12次跳转。

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=1]{logsearch.pdf}
	\caption{反向利用指数表进行二分估以计求得对数函数值} \label{fig:logsearch}
\end{figure}

计算出$ \delta(c,l)$后，$p_d(c,l) $可由指数查表与$ \delta(c,l)$结果共同计算。本文发现，由于不同的$ c $数值与不同$ l $数值，基于硬件计算$ \delta(c,l)$的时钟周期并不固定，例如当前c=1536，那么对数查找的起始位置便不在第一行，而在整体表的中间位置，这样搜索空间会缩小，因此查找次数也会变少。如图\ref{fig:searchtime}所示，假设流每个数据包大小统一为$ l=1000 $，当c的值越来越大，查找次数会往减小的趋势发展。

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=1]{searchtime.pdf}
	\caption{当流量中包长$l=1000$时利用指数表求对数函数值的查找次数} \label{fig:searchtime}
\end{figure}



3）存在问题。

本文总结上述分析，并将基于软件的DISCO算法硬件流水线在图展示。

\BiSubsection{优化}{aa}

1）符合DC抽象的算法优化方法

2）无偏估计证明




\BiSection{软硬一体化的系统实验平台}{aa} %2

\BiSubsection{软件}{aa}

\BiSubsection{硬件}{aa}

\BiSection{性能评估}{aa}

时间精度

吞吐

估算

cacti比较











在主机端，网络与计算的需求，

在第二章中提到NPU的可编程性最强且可以使用软件控制，由于他单核性能问题，尽管需要使程序员更换硬件思维，但业界普遍已经采取FPGA的方式来加速网络计算。

本章的主体是网络功能使用可编程硬件加速。

主机端网络开销最大的还属流量工程和网络内计算，因为每包处理，目前百G NIC 包速率已经达到150Mpps,对于每包操作的计算任务，CPU负载很大

1）分析软件到硬件卸载的可行性， 背景
	
	软件可扩展分析，



	

%流式处理《阿里巴巴大数据》page70


















